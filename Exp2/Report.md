# 软件需求工程
## 实验二 软件需求的优先级排序

### 一、实验目标
&emsp;&emsp;实现软件需求的优先级排序。

### 二、实验人员
* 161220085 刘心悦（25%）
* 171860595 陈少谦（25%）
* 171860663 马少聪（25%）
* 171860681 冯旭晨（25%）

### 三、实验思路 



### 四、实验步骤
1. 爬虫  
    1. 打开[Eclipse](https://bugs.eclipse.org/bugs/)，构造访问问答界面的请求，获取页面内容进行解析。
    2. 在页面调用开发者工具，查看bug的编号、bug描述和等级所对应的HTML源码，确定编号、描述和等级所对应的类和标签。
    3. 利用beautifulsoup模块的select函数进行查找。
    4. 利用re的compile函数和strinfo的sub函数对筛选后的源码再次筛选，将多余的内容通过正则表达式删去。
    5. 将处理后的编号、bug描述和等级输出到文件，文件名为“rawX.csv”,X从1到10，格式为每行对应一条bug记录，每个文件对应500条数据。
2. 分词
    1. 本次爬虫得到的数据中，10个文件中的5种类别的数据量并不平均，故要首先将各类别数据统一到一起。通过Classify.py文件将Data/Raw文件夹中的10个文件中的每行按重要类别分为5个文件，存储在Data/Class中。
    2. 通过Average.py文件将5个类别的数据平均分配到10个文件中，存储在Data/NewRaw中。
    3. 通过Separate.py文件将NewRaw中的10个文件进行分词处理：
        1. 利用nltk库中的word_tokenize进行分词
        2. 再使用stopwords去除文本中的停用词，包括常用的代词、介词、疑问词等。
        3. 将分词结果分别写入Data/Word的10个文件中。
3. 词转词向量


### 五、文件说明
1. 爬虫  
    &emsp;&emsp;爬虫功能实现在WebCrawler.py中。爬虫读取Eclipse上的bug信息，将每一条bug信息作为一条记录，存放在rawX.csv中，X从1到10，其中每一行代表一条记录，格式为每行四列，分别是bug编号/bug标题/bug描述/bug等级。<br>
    &emsp;&emsp;首先利用get_html函数获得bug列表网页的网页源码，接着使用get_address函数获取各个bug的地址，这里由于bug列表网页没有分页，一万多条跳转数据存放在一个网页中，如果使用get_html和get_address来获取各个bug的地址会非常缓慢，所以我将需要抓取的数据的bug编号复制下来，利用跳转网址和bug编号之间的联系直接访问每个bug的具体网页，略去了从bug列表网页中获取各个bug具体网页地址的过程。

2. 分词    

3. 词转词向量  
    &emsp;&emsp;词转词向量功能实现在Word2vec.py中。文件读取分词文件word.csv，输出词向量文件vec.csv。其中每一行代表一条记录的向量，向量的每个分量之间用逗号隔开。  


### 六、实验结果


### 七、反思改进


### 八、实验总结

