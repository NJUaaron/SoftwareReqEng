# 软件需求工程
## 实验二 软件需求的优先级排序

### 一、实验目标
&emsp;&emsp;实现软件需求的优先级排序。

### 二、实验人员
* 161220085 刘心悦（25%）
* 171860595 陈少谦（25%）
* 171860663 马少聪（25%）
* 171860681 冯旭晨（25%）

### 三、实验思路 



### 四、实验步骤
1. 爬虫  
    
2. 分词
    1. 本次爬虫得到的数据中，10个文件中的5种类别的数据量并不平均，故要首先将各类别数据统一到一起。通过Classify.py文件将Data/Raw文件夹中的10个文件中的每行按重要类别分为5个文件，存储在Data/Class中。
    2. 通过Average.py文件将5个类别的数据平均分配到10个文件中，存储在Data/NewRaw中。
    3. 通过Separate.py文件将NewRaw中的10个文件进行分词处理：
        1. 利用nltk库中的word_tokenize进行分词
        2. 再使用stopwords去除文本中的停用词，包括常用的代词、介词、疑问词等。
        3. 将分词结果分别写入Data/Word的10个文件中。
3. 词转词向量


### 五、文件说明
1. 爬虫  
    &emsp;&emsp;爬虫功能实现在WebCrawler.py中。爬虫读取Stackoverflow上的信息，将每一条问答作为一条记录，存放在raw.csv中，其中每一行代表一条记录，格式为每行三列，分别是序号/问题标题/问题答案。<br>
    &emsp;&emsp;首先利用get_html函数获得每页链接的网页源码，接着使用get_address函数获取每页中各个问题的地址，对于每个问题的地址，利用循环分别进行访问。在循环中，再次利用get_html函数访问得到网页源码，get_certain_qa函数得到每个问题网页的具体标题、问题和回答。

2. 分词    

3. 词转词向量  
    &emsp;&emsp;词转词向量功能实现在Word2vec.py中。文件读取分词文件word.csv，输出词向量文件vec.csv。其中每一行代表一条记录的向量，向量的每个分量之间用逗号隔开。  


### 六、实验结果


### 七、反思改进


### 八、实验总结

